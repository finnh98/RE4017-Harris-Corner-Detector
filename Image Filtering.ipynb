{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution / Cross-Correlation\n",
    "\n",
    "A Jupyter notebook showing the behaviour of various 2-d smoothing filters.\n",
    "\n",
    "FIrst some setup, load the required libraries and an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array(Image.open(\"fruits.jpg\").convert('L')) / np.float32(255.0)   # Normalised 0...1 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The image is {im.shape[0]} rows by {im.shape[1]} columns, with datatype {im.dtype}\")\n",
    "print(f\"Its min value is {im.min()} and its max is {im.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits Image', figsize=(6,6))\n",
    "plt.imshow(im, cmap='gray', vmin=0, vmax=1);  # Stop auto-scaling of brightness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic operation in all forms of image filtering is 2-D convolution (or, equivalently, 2-D cross-correlation).  \n",
    "\n",
    "In 2-D convolution the basic equation is:\n",
    "\n",
    "\\begin{equation}\n",
    "                Y[r,c] = \\sum_{u=-n}^{n} \\sum_{v=-m}^{m} H[u,v] \\; X[r-u,c-v] \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Here the input image is $X$, the output image is $Y$ and the convolution kernel is represented by $H$, and is assumed to be $(2n+1)\\times(2m+1)$.  This,  of course, assumes that the indices of the kernel can be negative, and ignores what happens at the edges of the image.\n",
    "\n",
    "In Python, as with most other languages, negative array indices are not allowed, so we can rewrite the equation to eliminate them (substituting $i = u + n$ and $j = v + m$ into the indices for $X$):\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "               Y[r,c] & = & \\sum_{i=0}^{2n+1} \\sum_{j=0}^{2m+1} H[i,j] \\; X[r-(i-n),c-(j-n)]\\\\\n",
    "                      & = & \\sum_{i=0}^{2n+1} \\sum_{j=0}^{2m+1} H[i,j] \\; X[r+n-i,c+m-j]\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The range of indices for the kernel $H$ now runs over $ i = 0 \\ldots 2n+1$, $j = 0 \\ldots 2m+1$.\n",
    "It is just necessary to ensure that the indices to $X$ never transgress the array bounds, and this equation can be implemented directly in interpreted Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_v1(X,H):\n",
    "    \"\"\"Naive, direct implementation of convolution.  Note edge effect: (n,m) border not filtered.\"\"\"\n",
    "    HR, HC = H.shape\n",
    "    assert HR % 2 == 1 and HC % 2 == 1, \"Odd-sized kernel required.\"\n",
    "    n, m = HR // 2, HC // 2\n",
    "    R, C = X.shape\n",
    "    Y = np.zeros(X.shape, X.dtype)\n",
    "    for r in range(n,R-n):\n",
    "        for c in range(m,C-m):\n",
    "            acc = 0.0\n",
    "            for i in range(HR):\n",
    "                for j in range(HC):\n",
    "                    acc += H[i,j] * X[r + n - i,c + m - j]\n",
    "            Y[r,c] = acc\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple test image to examine the effects of convolution filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((100,100),dtype='float32')\n",
    "X[30:70,30:70] = 1.0\n",
    "plt.figure()\n",
    "plt.imshow(X, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try out the convolution on various $N \\times N$ constant kernels.  Note that $N$ must be odd, and that the integral of the kernel (i.e., its sum) should be 1, so that the average brightness of the output image isn't changed relative to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makebox(k):\n",
    "    \"Create a (2k+1) x (2k+1) box filter kernel suitable for convolution filtering.\"\n",
    "    w = 2 * k + 1\n",
    "    return np.ones((w,w),dtype='float32') / w**2\n",
    "\n",
    "filter_ks = [1,2,5]\n",
    "Hs = [makebox(k) for k in filter_ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xouts = [convolution_v1(X,H) for H in Hs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Box filtering', figsize=(12,4))\n",
    "for i in range(len(Xouts)):\n",
    "    plt.subplot(1,3,(i+1))\n",
    "    plt.imshow(Xouts[i], cmap='gray')\n",
    "    w = 2 * filter_ks[i] + 1\n",
    "    plt.title(\"{} x {}\".format(w,w)) ; plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter does not change the brightness of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgbright(im):\n",
    "    \"Return the averge brightness of an image.\"\n",
    "    return np.sum(im.ravel())/(im.shape[0]*im.shape[1])\n",
    "    \n",
    "print(\"Average brightness, original image and filtered versions\")\n",
    "print([avgbright(Xi) for Xi in (X, Xouts[0], Xouts[1], Xouts[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are various box filters applied to the fruits image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3, H5, H11 = Hs   # Get kernels under convenient names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 x 3 convolution using interpreted Python.  Quite slow for a moderately-sized image.\n",
    "\n",
    "im1 = convolution_v1(im,H3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No real visible difference between this and the original.\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im1, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.title(\"Fruits image: 3x3 box filter\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.title(\"Original fruits image\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 x 5 convolution using interpreted Python.  Slower.\n",
    "\n",
    "im2 = convolution_v1(im,H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some slight visible differences appearing.\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im2, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.title(\"Fruits image: 5x5 box filter\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.title(\"Original fruits image\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11 x 11 convolution using interpreted Python.  Very slow.\n",
    "\n",
    "im3 = convolution_v1(im,H11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This time, quite distinct blurring.\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im3, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.title(\"Fruits image: 11x11 box filter\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "plt.title(\"Original fruits image\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution using Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution using interpreted Python is, unfortuantely, very slow.  Convolution is an expensive operation, with an $R\\times C$ source image and a $N \\times M$ kernel, the costs rise as $O(RCNM)$.  Clearly, interpreted Python isn't going to perform well.  On my 2.7GHz MacBook (admittedly an old machine), the $5 \\times 5$ kernel takes about $6$ seconds to convolve a $480 \\times 512$ image.  The $11 \\times 11$ kernel takes about $23$ seconds - $3.75$ times as long (note that $(11\\times 11)/(5\\times 5) = 4.84$).  You may get different numbers (the Anaconda implmentation on Windows seems to be faster), but the slowdown will be approximately the same.  The slowdown is sublinear because the inner for-loops have wider \"spans\" in the larger kernel, so the loop setup/teardown overhead is smaller as a proportion of overall run-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh5 = %timeit -o convolution_v1(im,H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh11 = %timeit -o convolution_v1(im,H11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Time ratio = {timeh11.average/timeh5.average:.4f}, \"\n",
    "      f\"kernel size ratio = {(11*11)/(5*5)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba is an optimising compiler for a subset of Python.  It can't compile the whole Python language, but is very good at compiling regular code involving loops and Numpy arrays (this is what it is designed for).\n",
    "\n",
    "One obvious approach to speeding up the filters is to recode the convolution using Numba, this should give a dramatic speed increase as we move from interpreted to compiled code, but with very minimal changes to the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a Numba implementation of a convolution filter.  It is as simple as prepreding the original convolution code with the <font color=\"#a000a0\"><tt>@njit</tt></font> Numba \"decorator\", saying, in effect, \"compile this function to machine code\".  Note that the input image is assumed to be single-channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def convolution_v2(X,H):\n",
    "    \"\"\"Numba implementation of convolution.  Note edge effect: (n,m) border not filtered.\"\"\"\n",
    "    HR, HC = H.shape\n",
    "    assert HR % 2 == 1 and HC % 2 == 1, \"Odd-sized kernel required.\"\n",
    "    n, m = HR // 2, HC // 2\n",
    "    R, C = X.shape\n",
    "    Y = np.zeros(X.shape, X.dtype)\n",
    "    for r in range(n,R-n):\n",
    "        for c in range(m,C-m):\n",
    "            acc = 0.0\n",
    "            for i in range(HR):\n",
    "                for j in range(HC):\n",
    "                    acc += H[i,j] * X[r + n - i,c + m - j]\n",
    "            Y[r,c] = acc\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im4 = convolution_v2(im, H5)    # Compiled Numba convolution using the 5 x 5 box kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits image, 5 x 5 convolution in Numba', figsize=(6,6))\n",
    "plt.imshow(im4, cmap='gray', vmin=0, vmax=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im5 = convolution_v2(im, H11)   # Compiled Numba convolution using the 11 x 11 box kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits image, 11 x 11 convolution using Numba', figsize=(6,6))\n",
    "plt.imshow(im5, cmap='gray', vmin=0, vmax=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(im2,im4)  # Are the results of the Numba convolution to same as those of the plain Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(im3,im5) # Comparing 11x11 filtering results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark the new Numba code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh5n = %timeit -o convolution_v2(im,H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh5.average/timeh5n.average   # Compiled vs interpreted for a 5 x 5 box filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh11n = %timeit -o convolution_v2(im,H11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the compiled to the interpreted convolution on the $11 \\times 11$ box kernel.  The dramtic speedup still applies.  This is for a Macbook Pro running Anaconda Python 3.7.9.  Times may vary for other implementations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh11.average / timeh11n.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H51 = makebox(25)   # 51 x 51 box filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im6 = convolution_v2(im, H51)   # Numba compiled using a 51 x 51 box.  Reasonably fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits image, 51 x 51 convolution using Numba', figsize=(6,6))\n",
    "plt.imshow(im6, cmap='gray');   # Autoscale to full range, this makes the image appear brighter than it really is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh51n = %timeit -o convolution_v2(im,H51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "51**2/11**2   # Ratio of kernel sizes for 51 x 51 and 11 x 11 box kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeh51n.average / timeh11n.average      # Ratio of run times.  Roughly the same increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a dramatic performance improvement, the compiled code is at least orders of magnitude faster than the interpreted code.  However, the $O(RCNM)$ scaling still applies, so bigger kernals are still quadratically slower than smaller ones even with Numpy assistance.\n",
    "\n",
    "Of course, the edges are not being filtered.  We can address this by assuming that the image is embedded in a \"sea of zeros\", so that indices going outside the image bounds contribute nothing to the final filtered image.  This allows filtering up the the image edges, but with a perceptable darkening.\n",
    "\n",
    "Another point to note is that something strange is happening at the edges of the filtered image.  Because our convolution assumes that the source image is bounded by zeros, a noticable \"darkening\" or discontinuity happens at the image edges, especially for big kernels like the $51 \\times 51$ example.\n",
    "\n",
    "One way to avoid this is to change the boundary conditions of the source image.  Instead of assuming that it is embedded in a \"sea of zeros\", let's assume that it is surrounded by \"reflections\" of itself.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def convolution_v3(X, H):\n",
    "    \"\"\"Numba-compiled 2-d convolution of image *X* with kernel *H*, extending out\n",
    "       to image edges.\"\"\"\n",
    "    HR, HC = H.shape\n",
    "    assert HR % 2 == 1 and HC % 2 == 1, \"Odd-sized kernel required.\"\n",
    "    n, m = HR // 2, HC // 2\n",
    "    R, C = X.shape\n",
    "    Y = np.zeros(X.shape, X.dtype)\n",
    "    for r in range(R):\n",
    "        for c in range(C):\n",
    "            acc = 0.0\n",
    "            for i in range(HR):\n",
    "                u = r + n - i\n",
    "                if u >= 0 and u < R:\n",
    "                    for j in range(HC):\n",
    "                        v = c + m - j\n",
    "                        if v >= 0 and v < C:\n",
    "                            acc += H[i,j] * X[u,v]\n",
    "            Y[r,c] = acc\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im7 = convolution_v3(im,H51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits image, 51 x 51 convolution using Numba with edge processing.', figsize=(6,6))\n",
    "plt.imshow(im7, cmap='gray');     # Autoscale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the edges are being filtered, but they are noticably darker than the image body.  This is because the wide ($51\\times 51$) convolution filter is assuming that anything beyound the edges of the image is $0$.  So consider $Y[0,0]$, it's going to get a lot of zeros, hence appear dim.\n",
    "\n",
    "One way to avoid this is to change the boundary conditions of the source image.  Instead of assuming that it is embedded in a \"sea of zeros\", let's assume that it is surrounded by \"reflections\" of itself.  \n",
    "\n",
    "\n",
    "Note one other thing going on in this code.  We pass the \"parallel=True\" flag to Numba and tell it that the outer loop ($r$ index) may be parallelize if possible.  This can speed up things by distributing the computation across multiple cores.  I find, for this code, a speedup using parallel of about 2 to 3 times over the non-parallel Numba version.  Numba is really an excellent system, allowing algorithms to be written and tested in simple Python, but then allowing fast run times through a clever, type-inferencing, JIT compiler combined with the ability to parallelize code, all with minimal effort on the part of the programmer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def convolution_v4(X, H):\n",
    "    \"\"\"Numba-compiled 2-d reflection convolution of image *X* with kernel *H*, \n",
    "       extending out to image edges.\"\"\"\n",
    "    HR, HC = H.shape\n",
    "    assert HR % 2 == 1 and HC % 2 == 1, \"Odd-sized kernel required.\"\n",
    "    n, m = HR // 2, HC // 2\n",
    "    R, C = X.shape\n",
    "    Y = np.zeros(X.shape, X.dtype)\n",
    "    for r in numba.prange(R):                 # Tell Numba that this loop may be parallelized.\n",
    "        for c in range(C):\n",
    "            acc = 0.0\n",
    "            for i in range(HR):\n",
    "                u = r + n - i\n",
    "                if u < 0: u = -u              # If u beyound left margin, reflect it back,\n",
    "                elif u >= R: u = 2*R-u-1      # and ditto if beyond right margin.\n",
    "                for j in range(HC):\n",
    "                    v = c + m - j\n",
    "                    if v < 0: v = -v          # If v above top of image, reflect it back,\n",
    "                    elif v >= C: v = 2*C-v-1  # and ditto if below bottom.\n",
    "                    acc += H[i,j] * X[u,v]\n",
    "            Y[r,c] = acc\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im6 = convolution_v4(im,H51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits image, 51 x 51 (reflection) convolution in Numba', figsize=(6,6))\n",
    "plt.imshow(im6, cmap='gray');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit convolution_v3(im,H51)     #  This is non-parallel Numba-compiled code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit convolution_v4(im,H51)     #  And this is Numba code with parallel=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the effects of the original zero padding and the new \"reflection\" padding on the top-left corner of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(convolution_v3(im,H11)[:50,:50],cmap='gray',vmin=0,vmax=1)\n",
    "plt.title('zero padding')\n",
    "plt.subplot(122)\n",
    "plt.imshow(convolution_v4(im,H11)[:50,:50],cmap='gray',vmin=0,vmax=1)\n",
    "plt.title('reflection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have a definiiton for \"circular convolution\".  This assumes that the image and the convolution kernel are both periodic.  It is important, because this is the assumption made implicitly by the Fourier transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def convolution_v5(X, H):\n",
    "    \"\"\"Numba-compiled 2-d convolution of image *X* with kernel *H*, extending out\n",
    "       to image edges.\"\"\"\n",
    "    HR, HC = H.shape\n",
    "    assert HR % 2 == 1 and HC % 2 == 1, \"Odd-sized kernel required.\"\n",
    "    n, m = HR // 2, HC // 2\n",
    "    R, C = X.shape\n",
    "    Y = np.zeros(X.shape, X.dtype)\n",
    "    for r in numba.prange(R):                 # Tell Numba to parallelize the outer loop.\n",
    "        for c in range(C):\n",
    "            acc = 0.0\n",
    "            for i in range(HR):\n",
    "                u = r + n - i\n",
    "                if u < 0: u += R              # If u beyound left margin, take from right side of image.\n",
    "                elif u >= R: u -= R           # If beyond right margin take from left side.\n",
    "                for j in range(HC):\n",
    "                    v = c + m - j\n",
    "                    if v < 0: v += C          # If v above top of image, take from bottom.\n",
    "                    elif v >= C: v -= C       # If v below bottom, take from top.\n",
    "                    acc += H[i,j] * X[u,v]\n",
    "            Y[r,c] = acc\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Fruits image, 51 x 51 circular convolution in Numba', figsize=(6,6))\n",
    "plt.imshow(convolution_v5(im,H51), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering using scipy.ndimage.filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library <font color=\"#2020ff\"><b>scipy.ndimage.filters</b></font> contains a set of predefined, and very efficiently implemented, routines for image filtering using both predefined and user-defined kernels.\n",
    "\n",
    "<p>\n",
    "The most important routine from <font color=\"#2020ff\"><b>scipy.ndimage.filters</b></font> is <font color=\"#2020ff\"><b>gaussian_filter</b></font>.  This implements an $N$-d Gaussian filter.  The $2$-d version implements the kernel:\n",
    "\n",
    "$$\n",
    "H(x,y) = {1 \\over 2 \\pi\\sigma^2} \\exp\\left( - {x^2 + y^2} \\over {2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the standard deviation of the kernel (in pixel units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage.filters as filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Gaussian Filtering', figsize=(12,10))\n",
    "sigmas = [2.0, 5.0, 10.0, 25.0]\n",
    "for i in range(len(sigmas)):\n",
    "    plt.subplot(2, int(np.ceil(len(sigmas)//2)), (i+1))\n",
    "    plt.imshow(filters.gaussian_filter(im,sigmas[i]), cmap=plt.cm.gray)\n",
    "    plt.title(\"S.D. $\\sigma$ = {}\".format(sigmas[i])) ; plt.axis('off') ;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Other filter types in the library include the nonlinear median, maximum and minimum filters.\n",
    "\n",
    "<p>\n",
    "Here is a typical use of a $3 \\times 3$ median filter for the removal of salt and pepper noise. The bridge image is $512 \\times 512 \\times 8$bits, and has been corrupted by $0.25\\%$ black $(0)$ pixels and $0.25\\%$ white $(255)$ ones.  A $3 \\times 3$ median filter is largely successful in removing this noise without blurring the underlying image too much.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_bridge = np.array(Image.open('bridge-sp-noise-005.png').convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = filters.median_filter(noisy_bridge,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Median Filtering\",figsize=(14,8))\n",
    "for i,im,title in zip([1,2], [noisy_bridge, bridge], [\"Original\", \"3x3 Median\"]):\n",
    "    plt.subplot(1,2,i) \n",
    "    plt.imshow(im, cmap=plt.cm.gray) ; plt.axis('off')\n",
    "    plt.title(title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Other useful rank-order filters are the minimum and maximum.  When used with binary images, these have special functions:\n",
    "<ol>\n",
    "<li> The maximum filter provides the <em>binary dilation</em> operation, which tends to \"fill in\" gaps in binary images.\n",
    "<li> The minimum filter provides the <em>binary erosion</em> operation, which tends to thin down thick lines.\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "Here binary dilation (a maximum filter) is first used to fill-in gaps in a binary image of a circle, then binary erosion (a minimum filter) thins down the shape.\n",
    "\n",
    "<p>\n",
    "Note the masks used for these filters.  The maximum filter uses a $3 \\times 3$ square mask, so the centre pixel is set in the output if <em>any</em> of the pixels in the input covered by the mask are set.  Such a mask is known as an \"8-neighbourhood\".  The minimum filter, on the other hand, uses a \"cross-shaped\" mask, known as a \"4-neighbourhood\". In this case, the output pixel at $(r,c)$ is only set in the output if <em>all</em> pixels at $(r,c)$, $(r-1,c)$, $(r+1,c)$, $(r,c-1)$ and $(r,c+1)$ are set in the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_circ = np.array(Image.open(\"broken-circle.png\").convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated_circ = filters.maximum_filter(broken_circ,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded_circ = filters.minimum_filter(dilated_circ,footprint=[[0,1,0],[1,1,1],[0,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Binary Dilation and Erosion\", figsize=(16,8))\n",
    "for i,im,title in zip([1,2,3], [broken_circ, dilated_circ, eroded_circ], \n",
    "                      [\"Original\", \"Dilation\", \"Erosion\"]):\n",
    "    plt.subplot(1,3,i) \n",
    "    plt.imshow(im, cmap=plt.cm.gray, interpolation='nearest') ; plt.axis('off') \n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sharpen an image by differencing an image and its smoothed version to generate edge regions, then add the difference back to the original.  The smoothing filter can be a box, or a Gaussian, the latter generally perfoming better, and tending to approximate a \"Laplacian of Gaussian\" operation, $\\Delta G = \\nabla^2 G = \\frac{\\partial^2 G}{\\partial x^2} + \\frac{\\partial^2 G}{\\partial y^2}$.\n",
    "\n",
    "Note that, in this section, we use the scipy.ndimage.filters implementation of the box filter, \"uniform_filter\".  Generally it is better to use the routines from scipy rather than \"roll your own\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbara = np.array(Image.open('barbara.png').convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbara = (barbara - barbara.min())/float(barbara.max() - barbara.min()) # 0..1 float image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_detail = barbara - filters.uniform_filter(barbara,5) # 5 x 5 box filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sharp = np.clip(barbara + b_detail, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Sharpening by Box Filter', figsize=(14,14))\n",
    "for i,im,title in zip([1,2,3], [barbara, b_detail, b_sharp], \n",
    "                      [\"Original\", \"Detail\", \"Sharpened (5x5 box)\"]):\n",
    "    plt.subplot(2,2,i) \n",
    "    plt.imshow(im, cmap=plt.cm.gray, interpolation='nearest') ; plt.axis('off') \n",
    "    plt.title(title);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian filters typically give better looking results.  Here we have a Gaussian with $\\sigma = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sharp_g3 = np.clip(2*barbara - filters.gaussian_filter(barbara,3), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Sharpening by Gaussian', figsize=(14,14))\n",
    "for i,im,title in zip([1,2,3], [barbara, b_sharp, b_sharp_g3], \n",
    "                      [\"Original\", \"5x5 box\", \"Gaussian, $\\sigma=3$\"]):\n",
    "    plt.subplot(2,2,i) \n",
    "    plt.imshow(im, cmap=plt.cm.gray, interpolation='nearest') ; plt.axis('off')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sharpening can also be controlled by the parameter $\\alpha$, where the final image is generated from $I' = (1+\\alpha)I - \\alpha(I \\ast H)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(image, sigma, alpha):\n",
    "    \"Sharpen a normalised (0..1) float image, sigma is the s.d. of a Gaussian.\"\n",
    "    return np.clip((1+alpha)*image - alpha*filters.gaussian_filter(image,sigma), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('Varying $\\\\alpha$', figsize=(14,14))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1) \n",
    "    plt.imshow(sharpen(barbara,3,2**i), cmap=plt.cm.gray, interpolation='nearest') ; plt.axis('off')\n",
    "    plt.title(f\"$\\\\alpha = {2**i}$, $\\\\sigma = 3$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution by Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to try to tackle the cost of doing convolution of images with big kernels (like the $51 \\times 51$ kernel shown earlier) is to use the fast Fourier transform.  Convolution in the \"time\" domain is equivalent to multiplication in the \"frequency\" domain, so the idea is to take the Fourier transforms of the source image and the convolution kernel, multiply them and take the inverse transform of their product.  Since the fast Fourier transform is efficient, this should be faster for large images.\n",
    "\n",
    "Numpy provides routines to take discrete Fourier transforms of images.  The basic routines needed are rfft2 (a FFT of a 2-d real source) and irfft2 (an inverse transform back to a 2-d real image from its 2-d frequency-domain representation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.fft as fft\n",
    "im = np.array(Image.open('fruits.jpg').convert('L')) / np.float32(255)\n",
    "f_im=fft.rfft2(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the transform of a real-valued (not complex) source is a complex array that has just over half the number of array elements.  Note that the entries of the transform are complex numbers, so the amount of information is the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_im.shape, f_im.dtype, im.shape, im.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are plots showing the log of the magnitude of the image's transform, and the phase information (in degrees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Fourier Transform of Image\", figsize=(12,6))\n",
    "for i,the_image,title in zip([1,2],\n",
    "                             [np.log(np.abs(f_im)+1),     # Note add 1 to allow log to work with 0's.\n",
    "                              np.angle(f_im, deg=True)],\n",
    "                             [\"Log Magitude\", \"Phase\"]):\n",
    "    plt.subplot(1,2,i)\n",
    "    plt.imshow(the_image,cmap='coolwarm',interpolation='none')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the transform of the kernel.  Here f_H51 is the discrete Fourier transform of a $51 \\times 51$ block smoothing filter.  Note that the transform has only a single component, at \"DC\", as the filter is a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_H51 = fft.rfft2(H51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_H51.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we plot the magnitude of the kernel and its phase.  Note that this time we don't use the log of the magnitude, because there is only one non-zero component.  Clearly we can't take the log of zero.\n",
    "\n",
    "The majority of the phase information is meaningless in this case, because it is associated with frequency components of zero magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Fourier Transform of Kernel\", figsize=(12,6))\n",
    "for i,the_image,title,color in zip([1,2],\n",
    "                                   [np.abs(f_H51),\n",
    "                                    np.angle(f_H51, deg=True)],\n",
    "                                   [\"Magitude\", \"Phase\"],\n",
    "                                   ['gray', 'coolwarm']):\n",
    "    plt.subplot(1,2,i)\n",
    "    plt.imshow(the_image,cmap=color,interpolation='none')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_H51.max(), f_H51.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem that immediately presents itself is that the transform of the image and the transform of the kernel are different sizes, so they can't be multiplied together in frequency space.  One way to overcome this is to pad the smaller input with zeros to make it the same size as\n",
    "the larger.  Then the transforms of the two sources will be the same size, and can be multiplied.\n",
    "\n",
    "Here the image, \"im\", is clearly expected to be larger than the kernel \"H\", so we first pad the kernel with zeros to make it the same size as the image, take the transforms of the image and the zero-padded kernel, multiply them, and take the inverse transform of the product.  This\n",
    "gives a first attempt at convolution using the Fourier transform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_fft_v1(im,H):\n",
    "    \"\"\"Perform convolution of an image by a kernel using the Fourier transform.\"\"\"\n",
    "    dft_im = fft.rfft2(im)\n",
    "    dft_H = fft.rfft2(H, im.shape)    # Note the second parameter.  This zero-pads H to the shape of im.\n",
    "    return fft.irfft2(dft_im * dft_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try this on the image \"im\" and a $51 \\times 51$ constant kernel.  It's a bit faster than direct convolution for this large kernel, and the result has similar looking statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_f = convolution_fft_v1(im,H51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we we display the results, we see that the fft-based convolution contains significant artifacts.  The output is shifted to the right and down relative to the source and the direct convolution, and there seem to be issues with the edges of the fft convolution.  We see that there appears to be some \"wrap around\", particularly from the bottom of the image to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_direct = convolution_v3(im,H51)   # Zero-padded convolution (image in a \"sea\" of zeros).\n",
    "\n",
    "plt.figure('FFT Convolution Artifacts',figsize=(12,12))\n",
    "plt.subplot(221)\n",
    "plt.imshow(out_f, cmap=plt.cm.gray,vmax=1)\n",
    "plt.title(\"Convolution by fft (51x51)\")\n",
    "plt.subplot(222)\n",
    "plt.imshow(out_direct, cmap=plt.cm.gray,vmax=1)\n",
    "plt.title(\"Direct convolution (51x51)\")\n",
    "plt.subplot(223)\n",
    "plt.imshow(np.abs(out_f - out_direct),cmap='jet',interpolation='nearest')\n",
    "plt.title(\"Differences\");\n",
    "plt.colorbar(shrink=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to carry out the convolution properly and eliminate these effects, we have to pad the source image and the kernel with zeros.  It can be shown (see Gonzalez and Woods, \"Digital Image Processing\", 3rd ed.: library, and Brigham, \"The Fast Fourier Transform\": (available on the web),\n",
    "that the needed padding is such as to make the padded images (both padded source and padded kernel) be of size $(R,C)$, where $R \\geq R_i + R_H - 1$ and $C \\geq C_i + C_H - 1$.  It is useful for efficiency to choose $R$ and $C$ even, and ideally, powers of 2.\n",
    "\n",
    "The resulting image is larger than the source image, it needs to be cropped.  The cropping is explained in Brigham. (See also the workbook \"Convolution and the FFT\", which explains the padding and shift behaviour for 1-d signals, available in this directory).\n",
    "\n",
    "Here is an implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convolution_fft_v2(im,H, verbose=False):\n",
    "    \"\"\"Perform convolution of an image by a kernel using the Fourier transform, this time\n",
    "       with proper padding of both the source image and the kernel.\n",
    "       \n",
    "       Assumes the kernel is odd-sized and symmetric around the origin.\"\"\"\n",
    "    R_i, C_i = im.shape\n",
    "    R_H, C_H = H.shape\n",
    "    d_R, d_C = R_H // 2, C_H // 2\n",
    "    R, C = (2**(np.ceil(np.log2([R_i + R_H - 1,C_i + C_H - 1])))).astype('int')\n",
    "    if verbose:\n",
    "        print(f\"Image is {R_i} x {C_i}, Kernel is {R_H} x {C_H}.\")\n",
    "        print(f\"Minimum padding is to {R_i + R_H - 1} x {C_i + C_H - 1}, \"\n",
    "              f\"FFT on {R} x {C}.\")\n",
    "    dft_im = fft.rfft2(im, (R,C))\n",
    "    dft_H = fft.rfft2(H, (R,C))\n",
    "    return fft.irfft2(dft_im * dft_H)[d_R:d_R+R_i,d_C:d_C+C_i]  # Extract useful part of result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_f_v2 = convolution_fft_v2(im, H51, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure('FFT Convolution Artifacts',figsize=(12,12))\n",
    "print(\"Padded FFT convolution: min and max values:\", out_f_v2.min(),out_f_v2.max())\n",
    "print(\"Direct, zero-padded convolution: min & max:\",out_direct.min(), out_direct.max())\n",
    "plt.subplot(221)\n",
    "plt.imshow(out_f_v2, cmap=plt.cm.gray, vmax=1)\n",
    "plt.title(\"Convolution by fft v2 (51x51)\")\n",
    "plt.subplot(222)\n",
    "plt.imshow(out_direct, cmap=plt.cm.gray, vmax=1)\n",
    "plt.title(\"Direct convolution (51x51)\")\n",
    "plt.subplot(223)\n",
    "plt.imshow(np.abs(out_f_v2 - out_direct), cmap='jet',interpolation='nearest')\n",
    "plt.title(\"Differences\")\n",
    "plt.colorbar(shrink=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the FFT convolution looks like a direct convolution with zero padding.  There are minor differences between the FFT and the direct convolutions, but these are very small and due to numerical noise (note that the differences are all in the $10^{-8}$ region)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The direct convolution scales as $O(RCNM)$, whereas the FFT scales as $O(RC \\log_2 R \\log_2 C)$.  The cutoff where it can be beneficial to employ FFT convolution has to be determined by experiment, but generally, for large kernels like $51 \\times 51$, it is an attractive option.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_direct_numba_h51 = %timeit -o convolution_v3(im,H51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fft_h51 = %timeit -o convolution_fft_v2(im,H51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"FFT Convolution speedup, 51x51 kernel: {time_direct_numba_h51.average/time_fft_h51.average:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for example, the FFT convolution is better than 15 times faster than direct convoution for the $51 \\times 51$ kernel.\n",
    "\n",
    "But it is slower for the $5 \\times 5$ kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_direct_numba_h5 = %timeit -o convolution_v3(im,H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fft_h5 = %timeit -o convolution_fft_v2(im, H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"FFT Convolution speedup, 5x5 kernel: {time_direct_numba_h5.average/time_fft_h5.average:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is about twice as fast for the $11 \\times 11$ kernel.  This illustrates that the FFT approach to convolution is attractive, albeit complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_direct_numba_h11 = %timeit -o convolution_v3(im,H11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fft_h11 = %timeit -o convolution_fft_v2(im, H11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"FFT Convolution speedup, 11x11 kernel: {time_direct_numba_h11.average/time_fft_h11.average:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperable Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach to speeding up convolution takes advantage of the fact that some kernels (not all) are separable.  This means that the 2-D convolution can be broken down into two 1-D convolutions.  The idea is that the overall 2-D convoution can be performed by first applying a 1-D convolution to the columns of the source image, then a second 1-D convolution to the rows of the 2-D array resulting from the first convolution.\n",
    "\n",
    "In 2-D convolution the basic equation is:\n",
    "\n",
    "\\begin{equation}\n",
    "                Y[u,v] = \\sum_{i=-n}^{n} \\sum_{j=-m}^{m} X[u-i,v-j] \\; H[i,j]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "If $H$ is seperable, then $H[i,j] = H[i] H[j]$, so:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "                Y[u,v] & = & \\sum_{i=-n}^{n} \\sum_{j=-m}^{m} X[u-i,v-j] \\; H[i,j] \\\\\n",
    "                       & = & \\sum_{i=-n}^{n} \\sum_{j=-m}^{m} X[u-i,v-j] \\; H[i] \\; H[j] \\\\\n",
    "                       & = & \\sum_{i=-n}^{n} \\; \\left( \\sum_{j=-m}^{m} X[u-i,v-j] H[j] \\right) \\; H[i]\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The term inside the brackets is a 1-D convolution over columns (because, inside the $j$-sum, $i$ is constant).  Similarly, once the convolution within the brackets is performed, the result depends on $i$ only, so we have a second 1-D convolution over rows.\n",
    "\n",
    "Here, for example, the $5 \\times 5$ 2-d convolution kernel, which is seperable, is carried out by first performing 1-d convolutions of a 5-element kernel to the rows of the source image, then a second convolution columnwise to the result of this.  The overall effect is the same as performing a 2-d convolution with a $5 \\times 5$ kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_sep_v1(im,Hr,Hc):\n",
    "    \"\"\"2-d convolution using a seperable kernel.  \n",
    "    \n",
    "              convolution_sep_v1(im,Hr,Hc)\n",
    "              \n",
    "       Parameter Hr must be the 1-d row component of an n x m seperable kernel, \n",
    "       and Hc the 1-d column component, such that outer(Hr,Hc) is the 2-D kernel.\n",
    "    \"\"\"\n",
    "    R, C = im.shape\n",
    "    N, M  = len(Hr), len(Hc)\n",
    "    assert N % 2 == 1 and M % 2 == 1, \"Dimensions of kernel must be odd lengths.\"\n",
    "    n, m = N // 2, M // 2 \n",
    "    #\n",
    "    # Part (1), convolutions down rows, all columns in parallel.\n",
    "    #\n",
    "    temp=np.zeros(im.shape,dtype=im.dtype)  # Temporary image holds results of row convolutions.\n",
    "    acc = np.zeros(C, dtype=im.dtype)       # Set of accumulators (1 per column) for row convolution calcs.\n",
    "    for r in range(R):\n",
    "        acc[:] = 0.0\n",
    "        for i in range(N):\n",
    "            u = r + n - i\n",
    "            if u >= 0 and u < R: acc += Hr[i] * im[u,:]  # All columns accumulate in parallel.\n",
    "        temp[r,:] = acc\n",
    "    #\n",
    "    # Part (2), convolutions across columns, all rows in parallel.\n",
    "    #\n",
    "    Y=np.zeros(im.shape,im.dtype)           # Y is output image\n",
    "    acc = np.zeros(R, dtype=im.dtype)       # Set of accmulators (1 per row) for column convol calculations.\n",
    "    for c in range(C):\n",
    "        acc[:] = 0.0\n",
    "        for j in range(M):\n",
    "            v = c + m - j\n",
    "            if v >= 0 and v < C: acc += Hc[j] * temp[:,v]  # All rows accumulate in parallel this time. \n",
    "        Y[:,c] = acc\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make a seperable component of a square $5 \\times 5$ kernel.  The point is that the outer product of this \"Hs5\" 1-D kernel with itself is the \"H5\" 2-D kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs5=np.ones(5)/5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this kernel to the seperable convolution code give the same results as direct 2-D convolution by a $5 \\times 5$ kernel (with some residual error due to the use of single-precision floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys5=convolution_sep_v1(im,Hs5,Hs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Ys5,cmap=plt.cm.gray,vmin=0,vmax=1)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imh5direct = convolution_v3(im,np.outer(Hs5,Hs5))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(imh5direct,cmap=plt.cm.gray,vmin=0,vmax=1)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(np.abs(Ys5-imh5direct),interpolation='nearest',cmap='hot')\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ys5.mean(), Ys5.std(), Ys5.min(), Ys5.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imh5direct.mean(), imh5direct.std(), imh5direct.min(), imh5direct.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, even though the seperable convolution above is implemented as interpreted Python with NumPy, it is quite close to the speed of the compiled Cython direct 2-D convolution.  This is due partly to the use that the seperable convolution makes of the very efficient NumPy routines for array addition and multiplication on slices, but more importantly because the seperable convolution has a run time that scales as $O(RC(N+M))$ instead of $O(RCNM)$ for the direct convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sep_interp_h5 = %timeit -o convolution_sep_v1(im,Hs5,Hs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_direct_numba_h5 = %timeit -o convolution_v3(im,np.outer(Hs5,Hs5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect is much more pronounced for a seperable version of the $51 \\times 51$ square kernel used earlier.  Here the separable kernel implementation in interpreted Python is <em>faster</em> than the Numba-compiled direct convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hs51=np.ones(51)/51.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit convolution_sep_v1(im,Hs51,Hs51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit convolution_v3(im,np.outer(Hs51,Hs51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed things up futher, we could try converting the seperable convolution code to Numba. The only change we have to make is to add the @njit decorator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def convolution_sep_v2(im, Hr, Hc):\n",
    "    \"\"\"2-d convolution using a seperable kernel, compiled with Numba.  \n",
    "    \n",
    "              convolution_sep_v2(im,Hr,Hc)\n",
    "              \n",
    "       Parameter Hr must be the 1-d row component of an n x m seperable kernel, \n",
    "       and Hc the 1-d column component, such that outer(Hr,Hc) is the 2-D kernel.\n",
    "       If Hc is omitted, it is assumed to be identical to Hr.\n",
    "    \"\"\"\n",
    "    #if not Hc: Hc = Hr                      # If no Hc supplied, use a copy of Hr for the col convols.\n",
    "    R, C = im.shape\n",
    "    N, M  = len(Hr), len(Hc)\n",
    "    assert N % 2 == 1 and M % 2 == 1, \"Dimensions of kernel must be odd lengths.\"\n",
    "    n, m = N // 2, M // 2 \n",
    "    #\n",
    "    # Part (1), convolutions down rows, all columns in parallel.\n",
    "    #\n",
    "    temp=np.zeros(im.shape,dtype=im.dtype)  # Temporary image holds results of row convolutions.\n",
    "    acc = np.zeros(C, dtype=im.dtype)       # Set of accumulators (1 per column) for row convolution calcs.\n",
    "    for r in range(R):\n",
    "        acc[:] = 0.0\n",
    "        for i in range(N):\n",
    "            u = r + n - i\n",
    "            if u >= 0 and u < R: acc += Hr[i] * im[u,:]  # All columns accumulate in parallel.\n",
    "        temp[r,:] = acc\n",
    "    #\n",
    "    # Part (2), convolutions across columns, all rows in parallel.\n",
    "    #\n",
    "    Y=np.zeros(im.shape,im.dtype)           # Y is output image\n",
    "    acc = np.zeros(R, dtype=im.dtype)       # Set of accmulators (1 per row) for column convol calculations.\n",
    "    for c in range(C):\n",
    "        acc[:] = 0.0\n",
    "        for j in range(M):\n",
    "            v = c + m - j\n",
    "            if v >= 0 and v < C: acc += Hc[j] * temp[:,v]  # All rows accumulate in parallel this time. \n",
    "        Y[:,c] = acc\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys5v2 = convolution_sep_v2(im, Hs5, Hs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Ys5, cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Ys5v2, cmap=plt.cm.gray)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(np.abs(imh5direct-Ys5v2), cmap=plt.cm.hot)\n",
    "plt.axis('off')\n",
    "plt.colorbar(shrink=0.75);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compiled Numba code working on the seperable version of the $5 \\times 5$ kernel is about $5$ - $6$ times faster than its interpreted counterpart, and somewhat faster than the direct $5 \\times 5$ kernel.  Of course, the differences become more pronounced for bigger images and bigger kernels.\n",
    "\n",
    "The implementations of filters in the scipy.ndimage.filters package are aware of linear separabliity, and make use of it whenever possible (for the uniform_filter and for the Gaussian filter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sep_numba_h5 = %timeit -o convolution_sep_v2(im,Hs5,Hs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sep_interp_h5.average / time_sep_numba_h5.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_direct_numba_h5.average / time_sep_numba_h5.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, convolution by separation depends on the kernel being seperable, i.e., $H[i,j] = H[i]H[j]$.  This is not generally true.  For example, a \"circular kernel\", where\n",
    "\n",
    "\\begin{equation}\n",
    "    H[i,j] = \\left\\{\\begin{array}{cl}  1  &  (i^2+j^2) > N^2 \\\\ 0  & otherwise \\end{array}\\right.\n",
    "\\end{equation}\n",
    "\n",
    "is not seperable.\n",
    "\n",
    "However, the important Gaussian kernel\n",
    "\n",
    "\\begin{equation}\n",
    "    H[i,j] = \\exp(-(i^2+j^2)/2\\sigma^2)\n",
    "\\end{equation}\n",
    "\n",
    "is seperable, and provides a good appraoch to implementing a \"circular-style\" kernel where the importance of the contribution of a pixel diminishes exponentially quickly with its distance from the current convolution centre.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
